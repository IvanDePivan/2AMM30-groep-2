{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPDWF/IZUNvOUnSG4yApEHI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IvanDePivan/2AMM30-groep-2-component-1/blob/main/Model_RE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rygoJk-wuPRg",
        "outputId": "b03eb68e-0a62-4867-a5c1-9e2d98f6558c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.23.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (23.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.0.1+cu118)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.17.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.12.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.10.0->accelerate) (3.27.6)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.10.0->accelerate) (17.0.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2.0.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2023.7.22)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.34.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.17.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.15,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.14.1)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n",
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.10/dist-packages (0.4.1)\n",
            "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.14.5)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.23.5)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from evaluate) (4.66.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.70.15)\n",
            "Requirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2023.6.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.17.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from evaluate) (23.2)\n",
            "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.18.0)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (9.0.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.8.6)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (6.0.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate) (3.12.4)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2.0.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2023.7.22)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2023.3.post1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->evaluate) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "import numpy as np\n",
        "import spacy\n",
        "from spacy.training.example import Example #holds information for one training instance\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "from spacy.scorer import Scorer\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import os\n",
        "import glob\n",
        "import re\n",
        "! pip install -U accelerate\n",
        "! pip install -U transformers\n",
        "! pip install evaluate"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Authenticate\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "# Get email of current Colab user\n",
        "import requests\n",
        "gcloud_token = !gcloud auth print-access-token\n",
        "gcloud_tokeninfo = requests.get('https://www.googleapis.com/oauth2/v3/tokeninfo?access_token=' + gcloud_token[0]).json()\n",
        "email = gcloud_tokeninfo['email']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Az_nCdduQht",
        "outputId": "e6af66fa-925f-4b11-ae65-262482f10a6d"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define filepath\n",
        "if email == 'tamaraexterkate93@gmail.com':\n",
        "  filename = \"/content/drive/MyDrive/TUe/TM/Exports/export_41675_project-41675-at-2023-10-04-09-37-9bbbec63.json\"\n",
        "elif email == 'n.v.diermen@student.tue.nl':\n",
        "  filename = \"/content/drive/MyDrive/Text Mining/export_41675_project-41675-at-2023-10-04-12-08-05f5e3f5.json\""
      ],
      "metadata": {
        "id": "bXBQjYyfuUii"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DATA = []\n",
        "\n",
        "# read json file\n",
        "with open(filename, 'rb') as fp:\n",
        "  training_data = json.load(fp)\n",
        "\n",
        "  # get text, labels, relations, benchmark for each article\n",
        "  for article in training_data:\n",
        "    entities = []\n",
        "    id_entities = []\n",
        "    relations = []\n",
        "    original_text = article.get('data').get('text')\n",
        "    if len(article.get('annotations')) == 5: # N=5\n",
        "      benchmark = True\n",
        "    else:\n",
        "      benchmark = False\n",
        "    for annotation in article.get('annotations'):\n",
        "      if annotation.get('ground_truth') == True: # only include ground truth\n",
        "        for ind, label in enumerate(annotation.get('result')):\n",
        "          if label.get('type') == 'labels':\n",
        "            start = label.get('value').get('start')\n",
        "            end = label.get('value').get('end')\n",
        "            id = label.get('id')\n",
        "            text = label.get('value').get('text')\n",
        "            label = label.get('value').get('labels')[0] # note: cannot deal with multiple labels\n",
        "            id_entities.append((start, end, label, id, text)) # WHY ORDER WEIRD FOR TRAIN[0]?\n",
        "            entities.append((start, end, label))\n",
        "          elif label.get('type') == 'relation':\n",
        "            from_id = label.get('from_id')\n",
        "            to_id = label.get('to_id')\n",
        "            relation = label.get('labels')[0] # note: cannot deal with multiple relations\n",
        "            relations.append((from_id, to_id, relation))\n",
        "          else:\n",
        "            print(\"found unknown label type (no label or relation)\")\n",
        "\n",
        "    # append article to training data as dictionary\n",
        "    DATA.append({\n",
        "    'text': original_text,\n",
        "    'entities': entities,\n",
        "    'id_entities': id_entities,\n",
        "    'relations': relations,\n",
        "    'benchmark': benchmark\n",
        "    })"
      ],
      "metadata": {
        "id": "8OkS1eAouWnq"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove entities with smallest span in case of overlapping entities\n",
        "def remove_overlap(entities):\n",
        "  # Initialize a list to store the final non-overlapping entities\n",
        "  final_entities = []\n",
        "\n",
        "  # Sort the entities by their start position in ascending order\n",
        "  entities.sort(key=lambda entity: entity[0])\n",
        "\n",
        "  # Iterate through the sorted entities\n",
        "  for entity in entities:\n",
        "      overlaps = False\n",
        "      for existing_entity in final_entities:\n",
        "          # Check for overlapping entities\n",
        "          if (entity[0] >= existing_entity[0] and entity[0] < existing_entity[1]) or \\\n",
        "            (entity[1] > existing_entity[0] and entity[1] <= existing_entity[1]):\n",
        "              overlaps = True\n",
        "              break\n",
        "      if not overlaps:\n",
        "          final_entities.append(entity)\n",
        "\n",
        "  return final_entities\n",
        "\n",
        "for article in DATA:\n",
        "  article['entities'] = remove_overlap(article['entities'])"
      ],
      "metadata": {
        "id": "2hoEFIJsubDd"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_test_split(data,test_size):\n",
        "  train_end= int(len(data)*(1-test_size))\n",
        "  return data[0:train_end], data[train_end:len(data)]"
      ],
      "metadata": {
        "id": "Ocg9uLglud6O"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train, test =  train_test_split(DATA,0.5)"
      ],
      "metadata": {
        "id": "M8v7Rne9ueyV"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def insert_markers(text, pair):\n",
        "\n",
        "  label_to_marker = {\n",
        "      'Winner': '[WINR]',\n",
        "      'Date': '[DATE]',\n",
        "      'Prizetype': '[PRZT]',\n",
        "      'Reason': '[REAS]',\n",
        "      'Nationality': '[NTLY]'\n",
        "  }\n",
        "\n",
        "  start_to_add = 0\n",
        "  end_to_add = 7\n",
        "  for ent in pair:\n",
        "    start = ent[0]\n",
        "    end = ent[1]\n",
        "    label = ent[2]\n",
        "    start += start_to_add\n",
        "    end += end_to_add\n",
        "    text = text[:start] + label_to_marker[label] + ' ' + text[start:]\n",
        "    text = text[:end] +' '+ label_to_marker[label] + text[end:]\n",
        "    start_to_add += 7*2\n",
        "    end_to_add += 7*2\n",
        "\n",
        "  return text"
      ],
      "metadata": {
        "id": "bE2fvOP2unV-"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_relation(pair, relations):\n",
        "  if pair[0][3] and pair[1][3]: # check if entities of pair exist in annotations\n",
        "    # see if and what relation there is between the entities of the pair\n",
        "    for relation in relations:\n",
        "      if (relation[0] == pair[0][3] and relation[1] == pair[1][3]) or (relation[1] == pair[0][3] and relation[0] == pair[1][3]):\n",
        "          return relation[2]\n",
        "  return 'no_relation'"
      ],
      "metadata": {
        "id": "-_oqeHMMuqGN"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def mark_data(data, NER_output=True):\n",
        "\n",
        "  # init data output and relations list\n",
        "  data_output = []\n",
        "  relations_output = []\n",
        "\n",
        "  # Iterate over each article in data\n",
        "  for article in data:\n",
        "\n",
        "    # get original text and convert to doc\n",
        "    text = article['text']\n",
        "\n",
        "    # get seperate list of winner entities and other entities in fixed format (start,end,label,id)\n",
        "    if NER_output:\n",
        "      # create doc\n",
        "      doc = best_nlp(text)\n",
        "\n",
        "      winners = []\n",
        "      others = []\n",
        "      for ent in doc.ents:\n",
        "        # check to what entity in the annotations the NER entity refers to\n",
        "        for original_ent in article['id_entities']:\n",
        "          ent_id = None # refer to None if entity is not in annotations\n",
        "          # otherwise overwrite with id of entity in annotations\n",
        "          if ent.start_char == original_ent[0] and ent.end_char == original_ent[1]:\n",
        "            # print(ent.text)\n",
        "            # print(original_ent[4])\n",
        "            ent_id = original_ent[3]\n",
        "            break\n",
        "        if ent.label_=='Winner':\n",
        "          winners.append((ent.start_char, ent.end_char, ent.label_, ent_id))\n",
        "        else:\n",
        "          others.append((ent.start_char, ent.end_char, ent.label_, ent_id))\n",
        "\n",
        "    else:\n",
        "      ents = article['id_entities']\n",
        "      winners = [ent for ent in ents if ent[2] =='Winner']\n",
        "      others = [ent for ent in ents if ent[2] !='Winner']\n",
        "\n",
        "    # make pairs for possible relations (winner + other)\n",
        "    pairs = []\n",
        "    for winner in winners:\n",
        "      for other in others:\n",
        "        if winner[0] < other[0]:\n",
        "          pairs.append((winner,other))\n",
        "        else:\n",
        "          pairs.append((other,winner))\n",
        "\n",
        "    # create new text with markers for each possible relation with winner\n",
        "    new_texts = [insert_markers(text, pair) for pair in pairs]\n",
        "    relations_output.extend([get_relation(pair, article['relations']) for pair in pairs])\n",
        "    data_output.extend(new_texts)\n",
        "\n",
        "  return data_output, relations_output"
      ],
      "metadata": {
        "id": "e1vLFzUiusSo"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# even vanaf train[1] omdat train[0] dus een gekke volgorde heeft in id_entity\n",
        "X_train, y_train = mark_data(train[1:], NER_output=False)\n",
        "X_test, y_test = mark_data(test, NER_output=False)\n",
        "\n",
        "for i in range(6):\n",
        "  print(X_train[i])\n",
        "  print(y_train[i] + '\\n')\n",
        "\n",
        "id2label = {0: \"no_relation\", 1: \"received_nobelprize_for\", 2: \"has_won\", 3: \"received_nobelprize_in\", 4: \"born_on\", 5: \"died_on\", 6: \"has_nationality\"}\n",
        "label2id = {\"no_relation\": 0, \"received_nobelprize_for\": 1, \"has_won\": 2, \"received_nobelprize_in\": 3, \"born_on\": 4, \"died_on\": 5, \"has_nationality\": 6}\n",
        "\n",
        "y_train = [label2id[label] for label in y_train]\n",
        "y_test = [label2id[label] for label in y_test]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VvtUjCB2u0r2",
        "outputId": "91fb27ac-21f7-4f6e-962b-a1d4e53320df"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[WINR] Max Karl Ernst Ludwig Planck [WINR] ([DATE] 23 April 1858 [DATE] – 4 October 1947) was a German theoretical physicist whose discovery of energy quanta won him the Nobel Prize in Physics in 1918.\n",
            "Planck made many substantial contributions to theoretical physics, but his fame as a physicist rests primarily on his role as the originator of quantum theory, which revolutionized human understanding of atomic and subatomic processes. In 1948, the German scientific institution Kaiser Wilhelm Society (of which Planck was twice president) was renamed Max Planck Society (MPG). The MPG now includes 83 institutions representing a wide range of scientific directions.\n",
            "Life and career.\n",
            "Planck came from a traditional, intellectual family. His paternal great-grandfather and grandfather were both theology professors in Göttingen; his father was a law professor at the University of Kiel and Munich. One of his uncles was also a judge.\n",
            "born_on\n",
            "\n",
            "[WINR] Max Karl Ernst Ludwig Planck [WINR] (23 April 1858 – [DATE] 4 October 1947 [DATE]) was a German theoretical physicist whose discovery of energy quanta won him the Nobel Prize in Physics in 1918.\n",
            "Planck made many substantial contributions to theoretical physics, but his fame as a physicist rests primarily on his role as the originator of quantum theory, which revolutionized human understanding of atomic and subatomic processes. In 1948, the German scientific institution Kaiser Wilhelm Society (of which Planck was twice president) was renamed Max Planck Society (MPG). The MPG now includes 83 institutions representing a wide range of scientific directions.\n",
            "Life and career.\n",
            "Planck came from a traditional, intellectual family. His paternal great-grandfather and grandfather were both theology professors in Göttingen; his father was a law professor at the University of Kiel and Munich. One of his uncles was also a judge.\n",
            "died_on\n",
            "\n",
            "[WINR] Max Karl Ernst Ludwig Planck [WINR] (23 April 1858 – 4 October 1947) was a [NTLY] German [NTLY] theoretical physicist whose discovery of energy quanta won him the Nobel Prize in Physics in 1918.\n",
            "Planck made many substantial contributions to theoretical physics, but his fame as a physicist rests primarily on his role as the originator of quantum theory, which revolutionized human understanding of atomic and subatomic processes. In 1948, the German scientific institution Kaiser Wilhelm Society (of which Planck was twice president) was renamed Max Planck Society (MPG). The MPG now includes 83 institutions representing a wide range of scientific directions.\n",
            "Life and career.\n",
            "Planck came from a traditional, intellectual family. His paternal great-grandfather and grandfather were both theology professors in Göttingen; his father was a law professor at the University of Kiel and Munich. One of his uncles was also a judge.\n",
            "has_nationality\n",
            "\n",
            "[WINR] Max Karl Ernst Ludwig Planck [WINR] (23 April 1858 – 4 October 1947) was a German theoretical physicist whose discovery of energy quanta won him the [PRZT] Nobel Prize in Physics [PRZT] in 1918.\n",
            "Planck made many substantial contributions to theoretical physics, but his fame as a physicist rests primarily on his role as the originator of quantum theory, which revolutionized human understanding of atomic and subatomic processes. In 1948, the German scientific institution Kaiser Wilhelm Society (of which Planck was twice president) was renamed Max Planck Society (MPG). The MPG now includes 83 institutions representing a wide range of scientific directions.\n",
            "Life and career.\n",
            "Planck came from a traditional, intellectual family. His paternal great-grandfather and grandfather were both theology professors in Göttingen; his father was a law professor at the University of Kiel and Munich. One of his uncles was also a judge.\n",
            "no_relation\n",
            "\n",
            "[WINR] Max Karl Ernst Ludwig Planck [WINR] (23 April 1858 – 4 October 1947) was a German theoretical physicist whose discovery of energy quanta won him the Nobel Prize in Physics in [DATE] 1918 [DATE].\n",
            "Planck made many substantial contributions to theoretical physics, but his fame as a physicist rests primarily on his role as the originator of quantum theory, which revolutionized human understanding of atomic and subatomic processes. In 1948, the German scientific institution Kaiser Wilhelm Society (of which Planck was twice president) was renamed Max Planck Society (MPG). The MPG now includes 83 institutions representing a wide range of scientific directions.\n",
            "Life and career.\n",
            "Planck came from a traditional, intellectual family. His paternal great-grandfather and grandfather were both theology professors in Göttingen; his father was a law professor at the University of Kiel and Munich. One of his uncles was also a judge.\n",
            "no_relation\n",
            "\n",
            "[WINR] Max Karl Ernst Ludwig Planck [WINR] (23 April 1858 – 4 October 1947) was a German theoretical physicist whose discovery of energy quanta won him the Nobel Prize in Physics in 1918.\n",
            "Planck made many substantial contributions to theoretical physics, but his fame as a physicist rests primarily on his role as the originator of quantum theory, which revolutionized human understanding of atomic and subatomic processes. In [DATE] 1948 [DATE], the German scientific institution Kaiser Wilhelm Society (of which Planck was twice president) was renamed Max Planck Society (MPG). The MPG now includes 83 institutions representing a wide range of scientific directions.\n",
            "Life and career.\n",
            "Planck came from a traditional, intellectual family. His paternal great-grandfather and grandfather were both theology professors in Göttingen; his father was a law professor at the University of Kiel and Munich. One of his uncles was also a judge.\n",
            "no_relation\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained('bert-base-cased')\n",
        "\n",
        "# add our labels as tokens to vocabulary\n",
        "special_tokens = [\"[WINR]\", \"[DATE]\", \"[REAS]\", \"[NTLY]\", \"[PRZT]\"]\n",
        "num_added_toks = tokenizer.add_tokens(special_tokens)\n",
        "print('We have added', num_added_toks, 'tokens')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D4VSZyNF_RBn",
        "outputId": "c10467e2-2bb6-452f-d2b4-d92f2512a7e5"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "We have added 5 tokens\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_function(examples):\n",
        "    return tokenizer(examples[\"text\"], truncation=True)"
      ],
      "metadata": {
        "id": "i2gwSj0Ma2_Y"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# Define a custom dataset class\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, input_data, labels, tokenizer, max_length):\n",
        "        self.input_data = input_data\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.input_data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = self.input_data[idx]\n",
        "        label = self.labels[idx]\n",
        "        encoding = self.tokenizer(\n",
        "            text,\n",
        "            truncation=True,\n",
        "            padding='max_length',\n",
        "            max_length=self.max_length,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "        return {\n",
        "            'input_ids': encoding['input_ids'].flatten(),\n",
        "            'attention_mask': encoding['attention_mask'].flatten(),\n",
        "            'labels': torch.tensor(label, dtype=torch.long)\n",
        "        }\n",
        "\n",
        "# Define hyperparameters\n",
        "max_seq_length = 128  # You can adjust this as needed\n",
        "batch_size = 2  # You can adjust this as needed\n",
        "\n",
        "# Create custom datasets\n",
        "train_dataset = CustomDataset(X_train, y_train, tokenizer, max_seq_length)\n",
        "test_dataset = CustomDataset(X_test, y_test, tokenizer, max_seq_length)\n",
        "\n",
        "# # Create data loaders\n",
        "# train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "# test_loader = DataLoader(test_dataset, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "y_EgGbvx_2JF"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import DataCollatorWithPadding\n",
        "\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
      ],
      "metadata": {
        "id": "IIbyjX2kGEVM"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import evaluate\n",
        "\n",
        "accuracy = evaluate.load(\"accuracy\")"
      ],
      "metadata": {
        "id": "50RJ4bqQGxpm"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    predictions = np.argmax(predictions, axis=1)\n",
        "    return accuracy.compute(predictions=predictions, references=labels)"
      ],
      "metadata": {
        "id": "mS2Q4xo0G1Sg"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    'bert-base-cased', num_labels=7, id2label=id2label, label2id=label2id\n",
        ")\n",
        "\n",
        "model.resize_token_embeddings(len(tokenizer))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hM6kpsdJG69m",
        "outputId": "a009f7fd-d477-409b-93eb-5983f15733b3"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Embedding(29001, 768)"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir=\"my_awesome_model\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=2,\n",
        "    per_device_eval_batch_size=2,\n",
        "    num_train_epochs=2,\n",
        "    weight_decay=0.01,\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    load_best_model_at_end=True,\n",
        "    push_to_hub=False,\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=test_dataset,\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113
        },
        "id": "5wmUsts5wgcU",
        "outputId": "733c295f-b370-46fb-8e99-d6f0069d1248"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='198' max='2416' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 198/2416 00:26 < 05:05, 7.27 it/s, Epoch 0.16/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}