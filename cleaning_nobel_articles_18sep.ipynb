{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IvanDePivan/2AMM30-groep-2-component-1/blob/tamara/cleaning_nobel_articles.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RlhkUVLQxeq0",
        "outputId": "582a99b1-f036-478d-f4a7-6da0b9bb819f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: ftfy in /usr/local/lib/python3.10/dist-packages (6.1.1)\n",
            "Requirement already satisfied: wcwidth>=0.2.5 in /usr/local/lib/python3.10/dist-packages (from ftfy) (0.2.6)\n",
            "Requirement already satisfied: srsly in /usr/local/lib/python3.10/dist-packages (2.4.7)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.3 in /usr/local/lib/python3.10/dist-packages (from srsly) (2.0.9)\n"
          ]
        }
      ],
      "source": [
        "!pip install ftfy\n",
        "!pip install srsly"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "hfRKGhr3nfKe"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "import ftfy\n",
        "import random\n",
        "import srsly\n",
        "import os\n",
        "import re\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bh222QelAvCQ",
        "outputId": "b125975d-78f2-48c9-cfd3-94ee65af7c95"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "YAoU7MABCI55"
      },
      "outputs": [],
      "source": [
        "# Get email of current Colab user\n",
        "import requests\n",
        "gcloud_token = !gcloud auth print-access-token\n",
        "gcloud_tokeninfo = requests.get('https://www.googleapis.com/oauth2/v3/tokeninfo?access_token=' + gcloud_token[0]).json()\n",
        "email = gcloud_tokeninfo['email']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p1u3JQVTCRaW",
        "outputId": "06850e7b-dbf5-4587-c4a8-f1c5beed85a1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/TUe/TM/Data/enwiki20230820-stripped-json\n"
          ]
        }
      ],
      "source": [
        "# Define notebook directory\n",
        "if email == 'tamaraexterkate93@gmail.com':\n",
        "  notebook_dir = \"/content/drive/MyDrive/TUe/TM/Data/enwiki20230820-stripped-json\"\n",
        "else:\n",
        "  notebook_dir = 'drive/MyDrive/enwiki20230820/raw/'\n",
        "\n",
        "print(notebook_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "P42IcTtaFMAb"
      },
      "outputs": [],
      "source": [
        "# Generate a list of file paths\n",
        "if email == 'tamaraexterkate93@gmail.com':\n",
        "  pathlist = [os.path.join(root, file) for root, dirs, files in os.walk(notebook_dir) for file in files]\n",
        "else:\n",
        "  pathlist = [p for p in Path(notebook_dir).glob('**/*') if p.is_file()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define notebook directory (Iris)\n",
        "#notebook_dir = r\"C:\\Users\\20182826\\Documents\\Data Science\\23-24 Jaar 2\\Text mining\\enwiki20230820-stripped-json\"\n",
        "#pathlist = pathlist = [p for p in Path(r\"C:\\Users\\20182826\\Documents\\Data Science\\23-24 Jaar 2\\Text mining\\enwiki20230820-stripped-json\").glob(\"**/*\") if p.is_file()]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "uSWvKDNhO7kj"
      },
      "outputs": [],
      "source": [
        "# Search terms\n",
        "search_terms = ['nobel', 'prize']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "78_ZDXVvxB0Y"
      },
      "outputs": [],
      "source": [
        "# Read files using srsly (generators)\n",
        "from itertools import chain\n",
        "\n",
        "def get_json_readers():\n",
        "  return chain.from_iterable(srsly.read_jsonl(path) for path in pathlist)\n",
        "\n",
        "def read_random_json():\n",
        "  data = srsly.read_jsonl(random.choice(pathlist))\n",
        "  articles = [article for article in data if len(article[\"text\"]) > 0]\n",
        "  articles = [article for article in articles if (re.search(term, article[\"text\"], re.IGNORECASE) for term in search_terms)]\n",
        "\n",
        "  return articles\n",
        "\n",
        "def read_all_json():\n",
        "  data = get_json_readers()\n",
        "  articles = [article for article in data if len(article[\"text\"]) > 0 and all(re.search(term, article[\"text\"], re.IGNORECASE) is not None for term in search_terms)]\n",
        "  print(f'found {len(articles)} nonempty nobel prize laureate articles')\n",
        "  return articles\n",
        "\n",
        "def read_all_json_owen():\n",
        "  data = get_json_readers()\n",
        "  articles = [article for article in data if \"Owen Willans Richardson\" in article[\"title\"]]\n",
        "  print(f'found {len(articles)} nonempty nobel prize laureate articles')\n",
        "  return articles\n",
        "\n",
        "def read_all_json_title():\n",
        "  data = get_json_readers()\n",
        "  articles = [article for article in data if all(re.search(term, article[\"title\"], re.IGNORECASE) is not None for term in search_terms)]\n",
        "  print(f'found {len(articles)} nonempty nobel prize laureate articles')\n",
        "  return articles"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "VFLWfl31WebS"
      },
      "outputs": [],
      "source": [
        "def clean_text(text):\n",
        "  # Note: the order of these regexes matter, due to '\\n' -> ' ' for instance resulting in repeated spaces\n",
        "  url_pattern = r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+'\n",
        "\n",
        "\n",
        "  ordered_list = re.compile(r'^[A-Z0-9]{1,2}\\.', re.MULTILINE)\n",
        "  cleaned_text = ftfy.fix_text(text)\n",
        "  cleaned_text = re.sub('\\(([;,] ?)+\\)', '\\(', cleaned_text) # Removes artifacts from within parentheses e.g. (; ; born in etc) -> (born in etc)\n",
        "  cleaned_text = re.sub('\\(.?\\)', '', cleaned_text) # Remove empty or 1 character parentheses e.g. \"( )\"\n",
        "  cleaned_text = re.sub('\\n', ' ', cleaned_text) # Remove newlines\n",
        "  cleaned_text = re.sub(ordered_list, '', cleaned_text) # Removes the first part of an ordered list (e.g. A. the cheese ->  the cheese)\n",
        "  cleaned_text = re.sub(' {2,}', ' ', cleaned_text) # Remove repeated spaces\n",
        "  cleaned_text = re.sub('[“”]', '\"', cleaned_text) # Remove smart double quotes, might also need one for smart single quotes\n",
        "  cleaned_text = re.sub('([12]\\d)(\\d{2})[–\\/](\\d{2}\\D)', r'\\1\\2-\\1\\3', cleaned_text)\n",
        "  cleaned_text = re.sub(url_pattern, '', cleaned_text)\n",
        "\n",
        "  return cleaned_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "JVFONaQi1zIL"
      },
      "outputs": [],
      "source": [
        "# # Not needed if you have the .json\n",
        "# articles = read_all_json()\n",
        "# srsly.write_json(os.path.join(notebook_dir, 'nobel_articles.json'), articles)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s3t9Z6jfp02k",
        "outputId": "8fd6ae86-a4f7-420f-f7f6-d2fab4f79515"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "14980\n"
          ]
        }
      ],
      "source": [
        "articles = srsly.read_json(os.path.join(notebook_dir, 'nobel_articles.json'))\n",
        "print(len(articles)) #63 missing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PR8yRFNqo2BY",
        "outputId": "755c3700-5077-46a7-b8f0-a6c861bc9851"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "12543\n"
          ]
        }
      ],
      "source": [
        "term = \"Physics|Chemistry|Physiology|Medicine|Literature|Peace|Economics\"\n",
        "articles = [article for article in articles if re.search(term, article[\"text\"], re.IGNORECASE) is not None]\n",
        "print(len(articles))  #65"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "efiQWOFYnBqS",
        "outputId": "ece8a2bf-9f42-46cf-9adb-dbeff693066b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4280\n"
          ]
        }
      ],
      "source": [
        "#word 'nobel' has to be in it 2 or more times\n",
        "articles = [article for article in articles if len(re.findall(r'nobel', article[\"text\"], re.IGNORECASE)) >= 2]\n",
        "print(len(articles)) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZjWCRx2abYCu",
        "outputId": "af5d2ef4-3ab0-490f-b7a8-c3061ef10ccb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2558\n"
          ]
        }
      ],
      "source": [
        "term = \"born\"\n",
        "articles = [article for article in articles if re.search(term, article[\"text\"], re.IGNORECASE) is not None]\n",
        "print(len(articles)) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YWpD0hdpgkH5",
        "outputId": "5df33bf7-0d71-4222-db59-a31c9d96df58"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2005\n"
          ]
        }
      ],
      "source": [
        "term = \"awarded|laureate\"\n",
        "articles = [article for article in articles if re.search(term, article[\"text\"], re.IGNORECASE) is not None]\n",
        "print(len(articles)) #269"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1845\n"
          ]
        }
      ],
      "source": [
        "# Words 'Price', 'List', 'University', 'History', 'College' not in title\n",
        "articles = [article for article in articles if all(word not in article[\"title\"] for word in ('Prize', 'List', 'University', 'History', 'College', 'Nobel', 'Science and technology'))]\n",
        "print(len(articles))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "NaDQYdW9WWNE"
      },
      "outputs": [],
      "source": [
        "articles_cleaned = [{key: (clean_text(value) if key == \"text\" else value) for key, value in article.items()} for article in articles]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "zz3SExs7qRlB"
      },
      "outputs": [],
      "source": [
        "# write cleaned articles to file\n",
        "srsly.write_json(os.path.join(notebook_dir, 'nobel_articles_cleaned.json'), articles_cleaned)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Testen"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "KprkU46mlx6G"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "with open(\"laureates.json\", 'r') as f:\n",
        "    winners_json = json.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "988\n",
            "270\n"
          ]
        }
      ],
      "source": [
        "i = 0\n",
        "#missing_uni = []\n",
        "print(len(winners_json))\n",
        "for winner in winners_json:\n",
        "    winner_found=False\n",
        "    for article in articles:\n",
        "        if article['title'] == winner:\n",
        "            winner_found=True\n",
        "            break\n",
        "    if winner_found==False:\n",
        "        #missing_uni.append(winner)\n",
        "        i+=1\n",
        "print(i)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
